Rate limiter dùng để control lượng traffic được gửi từ client hoặc service. Rate limiter giới hạn số client request gửi từ client trong một quãng thời gian nhất định, tất cả các request vượt ngưỡng đều sẽ bị block.
- Ngăn DoS.
- Giảm chi phí: cần ít server và resource hơn.
- Ngăn server bị overloaded.
![[Pasted image 20230416164532.png]]
![[Pasted image 20230416164548.png]]
![[Pasted image 20230416175922.png]]
Cloud microservices trở nên phổ biến và rate limiting thường được implement trong component gọi là API gateway. API gateway support rate limiting, SSL termination, authentication, IP whitelisting, Servicing static content, etc. Bây giờ ta chỉ cần biết nó là middleware support rate limiting.
Khi design rate limiter, ta cần tự đặt ra câu hỏi: Nó nên nằm ở gateway hay server-side? Một số guidelines:
- Tùy vào technology stack (programming language, cache service, etc.). Đảm bảo implement rate limiting sẽ hiệu quả ở trên server-side.
- Xác định thuật toán cho rate limiter.
- Nếu đang dùng microservice architecture và dùng gateway để xử lý authentication, IP whitelisting, etc thì ta có thể add rate limiter vào API gateway luôn.
# Thuật toán cho rate limiter
## Token bucket
- Một token bucket là một container có 1 capacity định trước. Token được refill vào bucket liên tục theo 1 rate nhất định. Khi bucket đầy thì không add được token vào nữa.
![[Pasted image 20230416213235.png]]
> Với hình trên, refiller sẽ đặt 2 token vào bucket mỗi giây, khi bucket đầy thì token vào sau sẽ bị overflow.

- Mỗi request tiêu tốn 1 token. Khi có request mới đến, ta check xem bucket còn token không:
	- Nếu còn thì request được thông qua và lấy token đó theo mình.
	- Nếu không thì request bị drop.
![[Pasted image 20230416213455.png]]
Ví dụ dưới là khi refiller sẽ refill 4 token mỗi giây:
![[Pasted image 20230416214056.png]]
=> Token bucket algorithm sẽ nhận 2 param là **bucket size** và **refill rate**.
Số lượng bucket sẽ tùy vào rate-limiter rule.
- Thường là mỗi API endpoint có 1 bucket riêng. VD chỉ cho user tạo 1 post 1 giây hay add 150 friend mỗi ngày,...
- Nếu muốn giới hạn theo IP thì mỗi IP sẽ cần 1 bucket.
- Còn nếu system chỉ cho phép tối đa 10000 request mỗi giây thì ta sẽ có global bucket shared cho tất cả các request.
|Ưu điểm|Nhược điểm|
|---|---|
| Dễ implement | Khó có thể điều chỉnh được 2 params để hệ thống hoạt động một cách hợp lý
| Memory efficient | |
| Vẫn cho phép phục vụ một lượng lớn request trong một thời gian ngắn, miễn là còn token ||
## Leaking bucket
Tương tự bucket algorithm, khác ở chỗ request được xử lý theo một rate cố định. Thường sử dụng FIFO queue.
- Khi request mới đến, hệ thống kiểm tra nếu queue đầy, chưa thì add vào queue, không thì drop request.
- Request được lấy ra từ queue sau 1 interval nhất định.
![[Pasted image 20230416215149.png]]
Leaking bucket nhận vào 2 tham số:
- Bucket size = queue size.
- Outflow rate: xác định số request được processed sau 1 rate.
|Ưu điểm|Nhược điểm|
|---|---|
|Memory efficient| Có 2 params nên khó thể config cho phù hợp |
|Request được xử lý theo fixed rate nên phù hợp cho use case mà stable outflow rate là cần thiết|A burst of traffic fills up the queue with old requests, and if they are not processed in time, recent requests will be rate limited|
## Fixed window counter
- Thuật toán chia timeline thành các fix-size time windows và gán cho mỗi window 1 counter.
- Mỗi khi có request tới thì sẽ tăng counter lên 1.
- Khi counter đạt đến 1 ngưỡng (threshold) định sẵn thì request mới sẽ bị drop cho đến khi một time windows mới bắt đầu.
> Dễ hiểu hơn là nó chỉ xử lý x request trong 1 time unit thôi. Khi đạt mức tối đa trong time unit đó thì phải đợi cho đến khi time windows mới bắt đầu.

![[Pasted image 20230416221526.png]]
Vấn đề với thuật toán này là nếu xảy ra burst of traffic tại ranh giới giữa các time windows thì só lượng request được thông qua sẽ nhiều hơn số lượng cho phép xử lý. VD hệ thống bên dưới chỉ xử lý tối đa 5 request 1 phút, còn mỗi time windows kéo dài một phút và bắt đầu tại giây đầu tiên của mỗi phút. Như hình dưới ta thấy trong 1 phút (*2:00:30 -> 2:01:30*) hệ thống phải xử lý 10 request (**gấp đôi**).
![[Pasted image 20230416221717.png]]
|Pros|Cons|
|---|---|
|Memory efficient|Tình huống bên trên|
|Dễ hiểu||
## Sliding window log
Sliding window log giải quyết vấn đề mà fixed window counter gặp phải.
- Thuật toán theo dõi timestamp của request. Timestamp data thường sẽ lưu trong cache.
- Khi request mới tới thì xóa mọi timestamp đã bị outdated trong log. Outdated timestamp là những timestamp < current timestamp - rate
- Add timestamp của request mới log.
- Nếu log size is the same hoặc bé hơn allowed count thì request được accept, không thì reject.
Pros: Rất chính xác.
Cons: Rất tốn bộ nhớ, timestamp của request bị reject cũng phải lưu lại.
![[Pasted image 20230416223618.png]]
## Sliding window counter
![[Pasted image 20230416223923.png]]
# High-level architecture
Basic idea rất đơn giản, ta cần một counter để keep track số request đã gửi từ user, IP,... Vậy counter nên được lưu ở đâu?
Dùng database thì chậm vì nó phải access tới disk => Chọn in-memory cache vì nó nhanh và support time-based expiration strategy.
![[Pasted image 20230416224347.png]]
High level design trên lại chưa trả lời được những câu hỏi sau:
- Rate limiting rules được tạo ra như thế nào và lưu ở đâu?
- Xử lý request bị rate limited như thế nào?
Detail design:
![[Pasted image 20230416224649.png]]
- Rules thường được lưu trên disk và sẽ được worker lấy từ disk lưu vào cache.
- Khi request gửi tới server nó sẽ đi qua rate limiter middleware trước. Rate limiter lấy rule từ cache và lấy counter từ Redis cache.
- Tùy vào response mà quyết định:
	- Forward tới API server.
	- Return *429 too many request* error tới client. Request bị rate limited sẽ bị **drop** hoặc **cho vào queue để xử lý sau**.
# In a distributed environment
Có 2 vấn đề xảy ra:
- Race condition
- Sync issue
## Race condition
![[Pasted image 20230416225109.png]]
Giả sử counter trong Redis là 3. Nếu 2 request đọc counter đồng thời trước khi 1 trong 2 ghi lại giá trị mới thì nó sẽ ghi lại giá trị counter + 1 nó tính được mà không quan tâm thread khác.
Có thể sử dụng lock để giải quyết vấn đề này nhưng sẽ slow down hệ thống. Có 2 strategy phổ biến là dùng *Lua script* hoặc *sorted sets data structure của Redis*.
## Sync issue
Để support hàng triệu user thì 1 rate limiter server sẽ không đủ => phải có nhiều, mà có nhiều thì phải sync.
![[Pasted image 20230416225517.png]]
Approach tốt là dùng một data store trung tâm như Redis:
![[Pasted image 20230416225615.png]]
# Kết luận
Một số additional talking point:
- Hard vs soft rate limiting
	- Hard là số request không được vượt quá threshold.
	- Soft là số request có thể vượt quá threshold trong một thời gian ngắn.
- Rate limiting tại các layer khác của hệ thống (OSI model).
- Design client tránh bị rate limited:
	- Sử dụng client cache để tranh gửi nhiều API call.
	- Không gửi nhiều request trong một khoảng thời gian ngắn.
	- Try catch exception hoặc error để recover từ exception.
	- Sử dụng back off time để retry logic.
