Trong bài này ta được yêu cầu thiết kế key-value store hỗ trợ các operation sau:
- `put(key, value)`
- `get(key)`
Không có design nào là hoàn hào mà luôn có sự đánh đổi giữa
- *read*, *write* và *memory usage*.
- *tính toàn vẹn của dữ liệu* và *tính sẵn sàng*.
Trong bài này ta thiết kế key-value store có những đặc điểm sau:
- size của key-value pair nhỏ (*< 10 KB*).
- Có khả năng lưu big data.
- High availability (tốc độ phản hồi nhanh, kể cả khi đang xảy ra lỗi).
- High scalability (có thể scale để support những tập dữ liệu lớn.
- Automatic scaling (khi thêm/xóa servers).
- Tunable consistency.
- Độ trễ thấp.
# Single server key-value store
Nếu chỉ có 1 server thì cách tốt nhất là dùng hash-table lưu in-memory. Tuy tốc độ access nhanh nhưng space lại giới hạn nên ta có thể optimize như sau:
- Nén dữ liệu.
- Chỉ lưu data thường dùng trong memory còn lại lưu trên disk.
Tuy nhiên, server đơn cũng vẫn sẽ đạt đến giới hạn của nó một cách nhanh chóng nên ta cần 1 *distributed key-value store* để hỗ trợ big data.
# Distributed key-value store
## CAP theorem
- **Consistency** (tính nhất quán): consistency có nghĩa là tất cả client đều thấy data giống nhau tại cùng thời điểm bất kể họ connect tới node nào.
- **Availability** (tính khả dụng): Bất cứ client nào request data cũng nhận response về kể cả khi có node nào đó bị sập.
- **Partition Tolerance** (dung sai phân vùng): Partition ở đây là kết nối giữa 2 node bị break. Partition tolerance có nghĩa là hệ thống tiếp tục vận hành bất xảy ra partition trong hệ thống.
CAP theorem nói rằng: *"Phải hy sinh 1 trong 3 tính chất trên để có được 2 tính chất còn lại"*.
![[Pasted image 20230418081811.png]]
Key-value store thường được phân loại theo 2 tính chất CAP mà nó support => có 3 loại: **CP/AP/CA** system.
Bởi vì network failure là không thể tránh khỏi nên CA system không thể tồn tại khi áp dụng thực tiễn (có tồn tại nhưng nó là RDBMS - không phải distributed system).
## Ideal situation
Trong điều kiện lý tưởng thì network partition không bao giờ xảy ra => data viết vào `n1` sẽ tự đồng replicated qua `n2` và `n3`.
=> Đạt được cả C và A.
![[Pasted image 20230418083244.png]]
## Real-world distributed systems
![[Pasted image 20230418083549.png]]
Vì partition là không thể tránh khỏi nên ta phải chọn giữa Availability và Consistency.
Trong VD trên, khi `n3` down:
- Nếu chọn **C** thì chúng ta phải block tất cả write operation tới `n1` và `n2` để tránh inconsistency giữa 3 server nhưng lại làm cho nó unavailable.
- Nếu chọn **A** thì system thì read có thể trả về stale data. Đổi lại `n1` và `n2` vẫn accept write và data sẽ được sync cho `n3` khi network partition được khắc phục.
# System components
## Data partition
Có 2 vấn đề cần giải quyết khi phân vùng data:
- Phân bố data đồng đều cho các server.
- Giảm thiểu data movement khi thêm/bớt server.
Ta có thể dùng *consitent hashing* để giải quyết vấn đề trên + một số ưu điểm:
- **Automatic scaling**.
- **Heterogeneity:** the number of virtual nodes for a server is proportional to the server capacity. For example, servers with higher capacity are assigned with more virtual nodes.
## Data replication
Để đạt được *high availability* và *reliability*, data phải được async replicate cho N server với N là param được config. VD hình dưới là N = 3. `key0` được replicated tại `s1` `s2` và `s3`.
![[Pasted image 20230418084637.png]]
Nhưng nếu có virtual node thì N node đầu tiên có thể map tới ít hơn N physical servers. Để tránh issue này thì ta chỉ lấy unique server.
Node trong cùng data center thường fail với nhau (VD mất điện, network issues hay natural disaster, etc.) => Ta replicate ra các node nằm ở các data center khác nhau (được kết nối với nhau thống qua *high speed networks*) để tăng reliability.
## Consistency
Vì data được replicate ra nhiều node nên ta cần sync với nhau. **Quorum consensus** đảm bảo consistency cho cả *read* và *write* operation.
> - **N**: number of replicas
> - **W**: Write quorum có size W. Để write operation thành công thì operation phải được *acknowledged* từ W replicas.
> - **R**: Read quorum có size R. Để read operation thành công thì nó phải đợi *response* từ ít nhất R replica.

![[Pasted image 20230418085654.png]]
 *coordinator* hoạt động như một Proxy giữa client và node. Write operation có W = 1 **không** có nghĩa là data chỉ lưu ở 1 node mà là coordinator chỉ xem như operation đó thành công nếu nhận được ít nhất *1 acknowledgment*. Còn data vẫn sẽ replicate ra toàn bộ N node.
 Việc chọn *W, R và N* thường phải đánh đổi giữa latency và consistency. Nếu W = 1 hoặc R = 1 thì operation sẽ returned nhanh chóng vì coordinator chỉ cần chờ 1 response từ bất cứ replica nào. Nếu > 2 thì query sẽ chậm hơn nhưng lại đảm bảo consistency tốt hơn.
 > Nếu *W + R > N* thì strong consistency được đảm bảo vì có ít nhất 1 node chứa latest data.
 > Một số setup khả thi:
 > - R = 1 và W = N: optimize for fast read
 > - W = 1 và R = N: optimize for fast write
 > - W + R > N, strong consistency (thường là N = 3, W = R = 2)
 > - W + R < N, strong consistency không được đảm bảo
 
## Consistency models
Là mức consistency của data:
- **Strong**: Luôn read được data mới nhất (client không bao giờ đọc được data cũ).
- **Weak**: Subsequent read operation có thể không thấy được data mới nhất.
- **Eventual**: Là 1 dạng của weak. Sau 1 khoảng thời gian đủ thì mới update xong ở mọi replicas.
Thường chỉ đạt được mức Strong khi không cho các replica accept read/write operation mới tới khi mọi replica đều đã accept operation write hiện tại (đang write thì không cho read/write mới). Nhưng dẫn đến availability thấp vì nó block new operation.
Eventual là recommend model.
## Inconsistency resolution: versioning
Replication giúp tăng availability nhưng gây ra inconsistency => dùng *versioning* và *vector lock*.
![[Pasted image 20230418103301.png]]
![[Pasted image 20230418103325.png]]
=> Xảy ra conflict giữa version cuối cùng, ta cần một versioning system để *detect và reconcile* conflict: **VECTOR CLOCK**.
> Vector clock là một [server, version] pair được gắn với data item dùng để check nếu 1 version là cũ hơn/mới hơn hay conflict với data khác.
> VD: *D([S1, v1], [S2, v2], …, [Sn, vn])* với D là data item, `v1` là version counter còn `s1` là server number.
> Nếu data item *D* được ghi vào server *Si* thì hệ thống sẽ thực hiện như sau:
> - Tăng *vi* nếu *[Si, vi]* đã tồn tại
> - Nếu không thì tạo entry *[Si, 1]*
> ![[Pasted image 20230418161003.png]]
> The vector clock D([s0, 1], [s1, 1])] is an ancestor of D([s0, 1], [s1, 2]). Therefore, no conflict is recorded.
> Two vector clocks indicate there is a conflict: D([s0, 1], [s1, 2]) and D([s0, 2], [s1, 1]).

Mặc dù vector clock có thể resolve conflict, có 2 downside đáng kể:
- Add complexity vào client vì cần phải implement conflict resolution.
- [server: version] có thể grow lên nhanh chóng. Để giải quyết vấn đề này ta cần đặt 1 threshold cho size của vector, khi độ dài vượt ngưỡng thì xóa những cặp cũ đi.
## Handling failures
Khi hệ thống scale lớn lên thì failure là điều khó tránh khỏi, thậm chí là thường xuyên => phải handle trường hợp failure.
### Failure detection
Sử dụng *decentralize failure detection method* như gossip protocol.
> *Gossip protocol*:
> - Mỗi node có một list bao gồm các node nào đang giao tiếp với nó (*membership list*) (*gồm member Id và heartbeat counter*).
> - Mỗi node sẽ định kỳ tự động tăng heartbeat counter của nó.
> - Mỗi node sẽ định kỳ gửi heartbeat tới một tập các node ngẫu nhiên, rồi từ các node này lại tiếp tục gửi đến một tập các node khác nữa. [Each node periodically sends heartbeats to a set of random nodes, which in turn propagate to another set of nodes.]
> - Khi một node nhận được heartbeat, nó update membership list.
> ![[Pasted image 20230419132416.png]]
>Vậy khi nào một node được coi là đã offline?
>- Ví dụ như node `s0` ở trên nhận thấy không nhận được heartbeat từ `s2` sau một khoảng thời gian dài, nó sẽ gửi heartbeat của nó (có cả thông tin của `s2`) tới một số node ngẫu nhiên, khi các node này cũng xác nhận là `s2` đã down thì `s0` sẽ mark `s2` đã down và propagating cho những node khác.
### Handling temporary failures
> So sánh temp failure và permanent failure:
> - Temp failure là những failure xảy ra vì một số nguyên nhân như: *network latency, hardware malfunction, software bugs*, short-lived và có thể được giải quyết bằng cách retry operation hoặc đợi hệ thống recover lại. (VD: *network timeouts, server crash, power outage*).
> - Permanent failure: xảy ra vì permanent hardware hoặc software fault như *disk failure, code bugs không thể fix được*. (VD: *hard disk crash, corrupted data, permanent software bugs...*)

Khi failure được phát hiện bằng gossip protocol thì hệ thống cần một cơ chế để đảm bảo *availability*.
VD như dưới, vì cơ chế **quorum consensus** thì read và write operator sẽ bị block.
> Bởi vì quorum (như đã học ở trên) chỉ dùng để đảm bảo *reliability* chứ không ***fault tolerant***.

![[Pasted image 20230419132956.png]]
Sử dụng technique gọi là "*sloppy quorum*" để cải thiện availability. Thay vì enforcing quorum requirement, hệ thống sẽ chọn *first W healthy servers for write* và *first R healthy servers for read* trên hash ring. Những server nào đã offline thì bị bỏ qua.
Nếu server A bị unavailable do network hay server failure thì sẽ có 1 server B khác tạm thời thay server đó xử lý request. Đến khi server A online trở lại, A sẽ được update những thay đổi từ khi nó offline + server B sẽ bàn giao công việc lại cho A.
Như VD trên thì khi `s2` sập, `s3` sẽ thay cho `s2` xử lý công việc.
### Handling permanent failures
*Anti-entropy*: so sánh từng piece of data trên replica và update mỗi replica thành version mới nhất.
### Handling data center outage
Chỉ cần có nhiều data center là được.
# System architecture diagram
![[Pasted image 20230419135652.png]]
- Client giao tiếp với key-value store thông qua API: `get` và `put`.
- Coordinator là một proxy nằm giữa client và store.
- Node được distributed trên ring sử dụng **consistent hashing**.
- System hoàn toàn decentralized nên add/move node là tự động.
- Data được replicated ở nhiều nodes.
- Không có SPOF bởi vì mỗi node đều có trách nhiệm như nhau.
Vì được thiết kế *decentralized* nên mỗi node trong task thực hiện các chức năng sau:
![[Pasted image 20230419140347.png]]
## Write path
Khi write request được directed tới 1 node:
![[Pasted image 20230419140446.png]]
## Read path
![[Pasted image 20230419140550.png]]
![[Pasted image 20230419140601.png]]
# Summary
![[Pasted image 20230419141146.png]]
> Một số thuật ngữ không hiểu trong bảng trên:
> - Heterogeneity: số lượng virtual node của một server tỉ lệ thuận với capacity của server. Server có capacity lớn thì cần nhiều virtual node.